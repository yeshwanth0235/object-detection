{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# from scipy.misc import imread, imresize\n",
    "from imageio import imread\n",
    "from skimage.transform import resize as imresize\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 40#experiment with the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 30 # No. of frames images\n",
    "y = 120 # Width of the image\n",
    "z = 120 # height\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size# calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    resized_image = imresize(image,(y,z)) #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    resized_image = resized_image/25 #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])#normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    resized_image = imresize(image,(y,z)) ##default resample=1 or 'P' which indicates PIL.Image.NEAREST\n",
    "                    resized_image = resized_image/255 #Normalize data\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/datasets/Project_data/train'\n",
    "val_path = '/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 07:39:01.349435: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-12-13 07:39:01.349496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14802 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1c:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model = Sequential()       \n",
    "model.add(Conv3D(8,kernel_size=(3,3,3),input_shape=(30, 120, 120, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))      \n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Softmax layer\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 120, 120, 8)   656       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 120, 120, 8)  32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 30, 120, 120, 16)  3472      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 120, 120, 16)  64       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 60, 60, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 15, 60, 60, 32)    4128      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 15, 60, 60, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 7, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 7, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 7, 30, 30, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 3, 15, 15, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 3, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 3, 15, 15, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 1, 7, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 2505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,867,365\n",
      "Trainable params: 6,866,869\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimiser = 'Adam' #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/3383535347.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 07:39:12.427750: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - ETA: 0s - loss: 6.7985 - categorical_accuracy: 0.3288Source path =  /datasets/Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-6.79850-0.32881-12.69998-0.19000.h5\n",
      "17/17 [==============================] - 166s 10s/step - loss: 6.7985 - categorical_accuracy: 0.3288 - val_loss: 12.7000 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.9130 - categorical_accuracy: 0.4399\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.91299-0.43990-7.09366-0.25000.h5\n",
      "17/17 [==============================] - 98s 6s/step - loss: 1.9130 - categorical_accuracy: 0.4399 - val_loss: 7.0937 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5938 - categorical_accuracy: 0.5123\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.59376-0.51226-8.70001-0.20000.h5\n",
      "17/17 [==============================] - 91s 6s/step - loss: 1.5938 - categorical_accuracy: 0.5123 - val_loss: 8.7000 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4035 - categorical_accuracy: 0.6006\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.40352-0.60062-8.18901-0.30000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 1.4035 - categorical_accuracy: 0.6006 - val_loss: 8.1890 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2911 - categorical_accuracy: 0.5911\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.29109-0.59105-2.45852-0.33333.h5\n",
      "17/17 [==============================] - 83s 5s/step - loss: 1.2911 - categorical_accuracy: 0.5911 - val_loss: 2.4585 - val_categorical_accuracy: 0.3333 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7804 - categorical_accuracy: 0.7197\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-0.78035-0.71972-2.02696-0.31667.h5\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.7804 - categorical_accuracy: 0.7197 - val_loss: 2.0270 - val_categorical_accuracy: 0.3167 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8087 - categorical_accuracy: 0.7163\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-0.80865-0.71626-1.40594-0.50000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.8087 - categorical_accuracy: 0.7163 - val_loss: 1.4059 - val_categorical_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6588 - categorical_accuracy: 0.7785\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.65880-0.77855-1.07821-0.66667.h5\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.6588 - categorical_accuracy: 0.7785 - val_loss: 1.0782 - val_categorical_accuracy: 0.6667 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5794 - categorical_accuracy: 0.7855\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.57944-0.78547-0.98629-0.60000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.5794 - categorical_accuracy: 0.7855 - val_loss: 0.9863 - val_categorical_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4641 - categorical_accuracy: 0.8304\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.46409-0.83045-1.32110-0.60000.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.4641 - categorical_accuracy: 0.8304 - val_loss: 1.3211 - val_categorical_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4660 - categorical_accuracy: 0.8339\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.46604-0.83391-1.14444-0.61667.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.4660 - categorical_accuracy: 0.8339 - val_loss: 1.1444 - val_categorical_accuracy: 0.6167 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3845 - categorical_accuracy: 0.8754\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.38454-0.87543-1.04463-0.60000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.3845 - categorical_accuracy: 0.8754 - val_loss: 1.0446 - val_categorical_accuracy: 0.6000 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2943 - categorical_accuracy: 0.9031\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.29432-0.90311-1.35432-0.51667.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.2943 - categorical_accuracy: 0.9031 - val_loss: 1.3543 - val_categorical_accuracy: 0.5167 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3026 - categorical_accuracy: 0.9031\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.30259-0.90311-1.35258-0.55000.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.3026 - categorical_accuracy: 0.9031 - val_loss: 1.3526 - val_categorical_accuracy: 0.5500 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2857 - categorical_accuracy: 0.9135\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.28570-0.91349-1.39927-0.56667.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2857 - categorical_accuracy: 0.9135 - val_loss: 1.3993 - val_categorical_accuracy: 0.5667 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2587 - categorical_accuracy: 0.9135\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.25871-0.91349-1.14776-0.61667.h5\n",
      "17/17 [==============================] - 72s 4s/step - loss: 0.2587 - categorical_accuracy: 0.9135 - val_loss: 1.1478 - val_categorical_accuracy: 0.6167 - lr: 6.2500e-05\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2586 - categorical_accuracy: 0.9066\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.25862-0.90657-1.02571-0.66667.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.2586 - categorical_accuracy: 0.9066 - val_loss: 1.0257 - val_categorical_accuracy: 0.6667 - lr: 6.2500e-05\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1857 - categorical_accuracy: 0.9343\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.18568-0.93426-0.81591-0.65000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.1857 - categorical_accuracy: 0.9343 - val_loss: 0.8159 - val_categorical_accuracy: 0.6500 - lr: 3.1250e-05\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2038 - categorical_accuracy: 0.9273\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.20381-0.92734-0.89973-0.66667.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.2038 - categorical_accuracy: 0.9273 - val_loss: 0.8997 - val_categorical_accuracy: 0.6667 - lr: 3.1250e-05\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2247 - categorical_accuracy: 0.9135\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.22466-0.91349-0.63403-0.75000.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.2247 - categorical_accuracy: 0.9135 - val_loss: 0.6340 - val_categorical_accuracy: 0.7500 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using the base model without and droupout we are clearly overfitting the data. It clearly overfitts lets try some tweaking with Droupout\n",
    "\n",
    "### categorical_accuracy: 0.9135\n",
    "### val_categorical_accuracy: 0.7500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_2 here removing batch normalisation and adding droupout and checking for any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model_2 = Sequential()       \n",
    "model_2.add(Conv3D(8,kernel_size=(3,3,3),input_shape=(30, 120, 120, 3),padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "model_2.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_2.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_2.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_2.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "#model.add(BatchNormalization()\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 2, 2)))      \n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(1000, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Dense(500, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "#Softmax layer\n",
    "\n",
    "model_2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 30, 120, 120, 16)  3472      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 15, 60, 60, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 15, 60, 60, 32)    4128      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 7, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 7, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 3, 15, 15, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 3, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 7, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,866,373\n",
      "Trainable params: 6,866,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimiser = 'Adam' #write your optimizer\n",
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us train and validate the model \n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/2073663117.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_2 = model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 2.3934 - categorical_accuracy: 0.2157Source path =  /datasets/Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-2.39345-0.21569-1.59812-0.34000.h5\n",
      "17/17 [==============================] - 162s 10s/step - loss: 2.3934 - categorical_accuracy: 0.2157 - val_loss: 1.5981 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5871 - categorical_accuracy: 0.2481\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.58707-0.24808-1.56016-0.21667.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 1.5871 - categorical_accuracy: 0.2481 - val_loss: 1.5602 - val_categorical_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.4865 - categorical_accuracy: 0.2888\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.48649-0.28883-1.40000-0.56667.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 1.4865 - categorical_accuracy: 0.2888 - val_loss: 1.4000 - val_categorical_accuracy: 0.5667 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3909 - categorical_accuracy: 0.4211\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.39086-0.42105-1.21923-0.53333.h5\n",
      "17/17 [==============================] - 87s 5s/step - loss: 1.3909 - categorical_accuracy: 0.4211 - val_loss: 1.2192 - val_categorical_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2882 - categorical_accuracy: 0.4345\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.28820-0.43450-1.35845-0.31667.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 1.2882 - categorical_accuracy: 0.4345 - val_loss: 1.3585 - val_categorical_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2736 - categorical_accuracy: 0.4291\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-1.27365-0.42907-1.07128-0.56667.h5\n",
      "17/17 [==============================] - 84s 5s/step - loss: 1.2736 - categorical_accuracy: 0.4291 - val_loss: 1.0713 - val_categorical_accuracy: 0.5667 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1761 - categorical_accuracy: 0.4844\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-1.17606-0.48443-1.22080-0.40000.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 1.1761 - categorical_accuracy: 0.4844 - val_loss: 1.2208 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0336 - categorical_accuracy: 0.5640\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-1.03360-0.56401-0.93888-0.65000.h5\n",
      "17/17 [==============================] - 83s 5s/step - loss: 1.0336 - categorical_accuracy: 0.5640 - val_loss: 0.9389 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0668 - categorical_accuracy: 0.5536\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-1.06684-0.55363-1.08832-0.53333.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 1.0668 - categorical_accuracy: 0.5536 - val_loss: 1.0883 - val_categorical_accuracy: 0.5333 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8299 - categorical_accuracy: 0.6609\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.82992-0.66090-0.89504-0.66667.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.8299 - categorical_accuracy: 0.6609 - val_loss: 0.8950 - val_categorical_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8735 - categorical_accuracy: 0.6090\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.87353-0.60900-0.77817-0.61667.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.8735 - categorical_accuracy: 0.6090 - val_loss: 0.7782 - val_categorical_accuracy: 0.6167 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7449 - categorical_accuracy: 0.6851\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.74490-0.68512-0.73822-0.66667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.7449 - categorical_accuracy: 0.6851 - val_loss: 0.7382 - val_categorical_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6197 - categorical_accuracy: 0.7509\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.61974-0.75087-0.83826-0.71667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.6197 - categorical_accuracy: 0.7509 - val_loss: 0.8383 - val_categorical_accuracy: 0.7167 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5843 - categorical_accuracy: 0.7889\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.58433-0.78893-0.70078-0.71667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.5843 - categorical_accuracy: 0.7889 - val_loss: 0.7008 - val_categorical_accuracy: 0.7167 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4930 - categorical_accuracy: 0.8304\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.49300-0.83045-0.80105-0.73333.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.4930 - categorical_accuracy: 0.8304 - val_loss: 0.8010 - val_categorical_accuracy: 0.7333 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4116 - categorical_accuracy: 0.8512\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.41160-0.85121-0.77245-0.70000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.4116 - categorical_accuracy: 0.8512 - val_loss: 0.7725 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3322 - categorical_accuracy: 0.8616\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.33221-0.86159-0.51416-0.86667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.3322 - categorical_accuracy: 0.8616 - val_loss: 0.5142 - val_categorical_accuracy: 0.8667 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2609 - categorical_accuracy: 0.9135\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.26094-0.91349-0.64841-0.80000.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.2609 - categorical_accuracy: 0.9135 - val_loss: 0.6484 - val_categorical_accuracy: 0.8000 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2535 - categorical_accuracy: 0.9135\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.25350-0.91349-0.96085-0.66667.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.2535 - categorical_accuracy: 0.9135 - val_loss: 0.9608 - val_categorical_accuracy: 0.6667 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2017 - categorical_accuracy: 0.9239\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.20166-0.92388-0.46942-0.80000.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.2017 - categorical_accuracy: 0.9239 - val_loss: 0.4694 - val_categorical_accuracy: 0.8000 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Let us fit the model\n",
    "\n",
    "history_2 = model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The modelling with Droupout doesn't show the much improvement. Still overfitting the data\n",
    "\n",
    "### categorical_accuracy: 0.9239\n",
    "### val_categorical_accuracy: 0.8000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_3 Here we will add both Batchnormalisation and Droupout and check if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model_3 = Sequential()       \n",
    "model_3.add(Conv3D(8,kernel_size=(3,3,3),input_shape=(30, 120, 120, 3),padding='same'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(Activation('relu'))\n",
    "\n",
    "model_3.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_3.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_3.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_3.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))      \n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model_3.add(Flatten())\n",
    "\n",
    "model_3.add(Dense(1000, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "model_3.add(Dense(500, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "#Softmax layer\n",
    "\n",
    "model_3.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_10 (Conv3D)          (None, 30, 120, 120, 8)   656       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 30, 120, 120, 8)  32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " conv3d_11 (Conv3D)          (None, 30, 120, 120, 16)  3472      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 30, 120, 120, 16)  64       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 15, 60, 60, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_12 (Conv3D)          (None, 15, 60, 60, 32)    4128      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 15, 60, 60, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 7, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 7, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 7, 30, 30, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " max_pooling3d_10 (MaxPoolin  (None, 3, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_14 (Conv3D)          (None, 3, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 3, 15, 15, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_11 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 2505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,867,365\n",
      "Trainable params: 6,866,869\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimiser = 'Adam' #write your optimizer\n",
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us train and validate the model \n",
    "\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/2109916619.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_3 = model_3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 8.5242 - categorical_accuracy: 0.2685Source path =  /datasets/Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-8.52417-0.26848-4.35064-0.24000.h5\n",
      "17/17 [==============================] - 168s 10s/step - loss: 8.5242 - categorical_accuracy: 0.2685 - val_loss: 4.3506 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.7613 - categorical_accuracy: 0.4220\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.76130-0.42199-2.68561-0.26667.h5\n",
      "17/17 [==============================] - 100s 6s/step - loss: 1.7613 - categorical_accuracy: 0.4220 - val_loss: 2.6856 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3530 - categorical_accuracy: 0.4986\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.35295-0.49864-2.05626-0.20000.h5\n",
      "17/17 [==============================] - 94s 6s/step - loss: 1.3530 - categorical_accuracy: 0.4986 - val_loss: 2.0563 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2547 - categorical_accuracy: 0.5232\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.25473-0.52322-1.48767-0.46667.h5\n",
      "17/17 [==============================] - 88s 6s/step - loss: 1.2547 - categorical_accuracy: 0.5232 - val_loss: 1.4877 - val_categorical_accuracy: 0.4667 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0961 - categorical_accuracy: 0.5591\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.09606-0.55911-2.61853-0.30000.h5\n",
      "17/17 [==============================] - 85s 5s/step - loss: 1.0961 - categorical_accuracy: 0.5591 - val_loss: 2.6185 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0550 - categorical_accuracy: 0.6505\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-1.05498-0.65052-4.16824-0.28333.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 80s 5s/step - loss: 1.0550 - categorical_accuracy: 0.6505 - val_loss: 4.1682 - val_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9203 - categorical_accuracy: 0.6540\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-0.92027-0.65398-5.03505-0.28333.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.9203 - categorical_accuracy: 0.6540 - val_loss: 5.0350 - val_categorical_accuracy: 0.2833 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7032 - categorical_accuracy: 0.7197\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.70317-0.71972-5.71525-0.20000.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.7032 - categorical_accuracy: 0.7197 - val_loss: 5.7152 - val_categorical_accuracy: 0.2000 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6127 - categorical_accuracy: 0.7543\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.61269-0.75433-6.85088-0.15000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.6127 - categorical_accuracy: 0.7543 - val_loss: 6.8509 - val_categorical_accuracy: 0.1500 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5130 - categorical_accuracy: 0.7993\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.51305-0.79931-6.88122-0.18333.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.5130 - categorical_accuracy: 0.7993 - val_loss: 6.8812 - val_categorical_accuracy: 0.1833 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4341 - categorical_accuracy: 0.8201\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.43414-0.82007-6.66245-0.25000.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.4341 - categorical_accuracy: 0.8201 - val_loss: 6.6624 - val_categorical_accuracy: 0.2500 - lr: 1.2500e-04\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5033 - categorical_accuracy: 0.8166\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.50331-0.81661-7.42139-0.23333.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.5033 - categorical_accuracy: 0.8166 - val_loss: 7.4214 - val_categorical_accuracy: 0.2333 - lr: 1.2500e-04\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3915 - categorical_accuracy: 0.8789\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.39147-0.87889-6.59131-0.30000.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.3915 - categorical_accuracy: 0.8789 - val_loss: 6.5913 - val_categorical_accuracy: 0.3000 - lr: 6.2500e-05\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4126 - categorical_accuracy: 0.8547\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.41263-0.85467-7.93590-0.23333.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.4126 - categorical_accuracy: 0.8547 - val_loss: 7.9359 - val_categorical_accuracy: 0.2333 - lr: 6.2500e-05\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4479 - categorical_accuracy: 0.8339\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.44791-0.83391-5.93697-0.38333.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.4479 - categorical_accuracy: 0.8339 - val_loss: 5.9370 - val_categorical_accuracy: 0.3833 - lr: 3.1250e-05\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3484 - categorical_accuracy: 0.8754\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.34837-0.87543-6.67520-0.28333.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.3484 - categorical_accuracy: 0.8754 - val_loss: 6.6752 - val_categorical_accuracy: 0.2833 - lr: 3.1250e-05\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3807 - categorical_accuracy: 0.8720\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.38068-0.87197-7.71678-0.26667.h5\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.3807 - categorical_accuracy: 0.8720 - val_loss: 7.7168 - val_categorical_accuracy: 0.2667 - lr: 1.5625e-05\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3546 - categorical_accuracy: 0.8754\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.35462-0.87543-6.44023-0.35000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.3546 - categorical_accuracy: 0.8754 - val_loss: 6.4402 - val_categorical_accuracy: 0.3500 - lr: 1.5625e-05\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4481 - categorical_accuracy: 0.8478\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.44808-0.84775-7.48144-0.20000.h5\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.4481 - categorical_accuracy: 0.8478 - val_loss: 7.4814 - val_categorical_accuracy: 0.2000 - lr: 7.8125e-06\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4528 - categorical_accuracy: 0.8166\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.45283-0.81661-5.64128-0.40000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.4528 - categorical_accuracy: 0.8166 - val_loss: 5.6413 - val_categorical_accuracy: 0.4000 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By adding both batchnormalisation and droupout didn't heled it made the model worse \n",
    "\n",
    "### categorical_accuracy: 0.8166\n",
    "### val_categorical_accuracy: 0.4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture 2 - Conv2D + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model_4 = Sequential()   \n",
    "model_4.add(TimeDistributed(Conv2D(16, (3, 3),padding='same', activation='relu'),input_shape=(x,y,z,3)))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_4.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    \n",
    "model_4.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_4.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model_4.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_4.add(LSTM(64))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "# Dense layer \n",
    "model_4.add(Dense(64,activation='relu'))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "# Softmax layer\n",
    "model_4.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 30, 120, 120, 8)   656       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 30, 120, 120, 16)  3472      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 15, 60, 60, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 15, 60, 60, 32)    4128      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 7, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 7, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 3, 15, 15, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 3, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 7, 7, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 2505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,866,373\n",
      "Trainable params: 6,866,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = 'Adam' #write your optimizer\n",
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/2157803987.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_4 = model_4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5530 - categorical_accuracy: 0.3092Source path =  /datasets/Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-1.55297-0.30920-1.62099-0.27000.h5\n",
      "17/17 [==============================] - 169s 10s/step - loss: 1.5530 - categorical_accuracy: 0.3092 - val_loss: 1.6210 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3649 - categorical_accuracy: 0.4348\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.36486-0.43478-1.72114-0.25000.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 1.3649 - categorical_accuracy: 0.4348 - val_loss: 1.7211 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2901 - categorical_accuracy: 0.4850\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.29013-0.48501-1.81970-0.20000.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 96s 6s/step - loss: 1.2901 - categorical_accuracy: 0.4850 - val_loss: 1.8197 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1598 - categorical_accuracy: 0.5263\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.15980-0.52632-1.80989-0.15000.h5\n",
      "17/17 [==============================] - 87s 5s/step - loss: 1.1598 - categorical_accuracy: 0.5263 - val_loss: 1.8099 - val_categorical_accuracy: 0.1500 - lr: 5.0000e-04\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0850 - categorical_accuracy: 0.5655\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.08501-0.56550-1.94712-0.25000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 91s 6s/step - loss: 1.0850 - categorical_accuracy: 0.5655 - val_loss: 1.9471 - val_categorical_accuracy: 0.2500 - lr: 5.0000e-04\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0277 - categorical_accuracy: 0.5813\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-1.02766-0.58131-1.83306-0.26667.h5\n",
      "17/17 [==============================] - 88s 5s/step - loss: 1.0277 - categorical_accuracy: 0.5813 - val_loss: 1.8331 - val_categorical_accuracy: 0.2667 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0211 - categorical_accuracy: 0.5848\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-1.02110-0.58478-1.71383-0.31667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 1.0211 - categorical_accuracy: 0.5848 - val_loss: 1.7138 - val_categorical_accuracy: 0.3167 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9384 - categorical_accuracy: 0.6298\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.93838-0.62976-1.58039-0.31667.h5\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.9384 - categorical_accuracy: 0.6298 - val_loss: 1.5804 - val_categorical_accuracy: 0.3167 - lr: 1.2500e-04\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9225 - categorical_accuracy: 0.6713\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.92246-0.67128-1.34602-0.46667.h5\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.9225 - categorical_accuracy: 0.6713 - val_loss: 1.3460 - val_categorical_accuracy: 0.4667 - lr: 1.2500e-04\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9684 - categorical_accuracy: 0.6228\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.96835-0.62284-1.32221-0.40000.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.9684 - categorical_accuracy: 0.6228 - val_loss: 1.3222 - val_categorical_accuracy: 0.4000 - lr: 1.2500e-04\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8519 - categorical_accuracy: 0.6851\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.85193-0.68512-1.27955-0.43333.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.8519 - categorical_accuracy: 0.6851 - val_loss: 1.2796 - val_categorical_accuracy: 0.4333 - lr: 1.2500e-04\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8368 - categorical_accuracy: 0.7059\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.83683-0.70588-1.31377-0.40000.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.8368 - categorical_accuracy: 0.7059 - val_loss: 1.3138 - val_categorical_accuracy: 0.4000 - lr: 1.2500e-04\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8424 - categorical_accuracy: 0.7093\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.84241-0.70934-1.25154-0.46667.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.8424 - categorical_accuracy: 0.7093 - val_loss: 1.2515 - val_categorical_accuracy: 0.4667 - lr: 1.2500e-04\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7992 - categorical_accuracy: 0.7024\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.79922-0.70242-1.14710-0.55000.h5\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.7992 - categorical_accuracy: 0.7024 - val_loss: 1.1471 - val_categorical_accuracy: 0.5500 - lr: 1.2500e-04\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7679 - categorical_accuracy: 0.7543\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.76795-0.75433-1.17820-0.55000.h5\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.7679 - categorical_accuracy: 0.7543 - val_loss: 1.1782 - val_categorical_accuracy: 0.5500 - lr: 1.2500e-04\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7793 - categorical_accuracy: 0.7301\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.77928-0.73010-1.20164-0.53333.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.7793 - categorical_accuracy: 0.7301 - val_loss: 1.2016 - val_categorical_accuracy: 0.5333 - lr: 1.2500e-04\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7745 - categorical_accuracy: 0.7405\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.77445-0.74048-1.16459-0.56667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.7745 - categorical_accuracy: 0.7405 - val_loss: 1.1646 - val_categorical_accuracy: 0.5667 - lr: 6.2500e-05\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7305 - categorical_accuracy: 0.7509\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.73054-0.75087-1.18606-0.46667.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.7305 - categorical_accuracy: 0.7509 - val_loss: 1.1861 - val_categorical_accuracy: 0.4667 - lr: 6.2500e-05\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7447 - categorical_accuracy: 0.7647\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.74468-0.76471-1.12101-0.58333.h5\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.7447 - categorical_accuracy: 0.7647 - val_loss: 1.1210 - val_categorical_accuracy: 0.5833 - lr: 3.1250e-05\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7610 - categorical_accuracy: 0.7163\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.76105-0.71626-0.93998-0.61667.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.7610 - categorical_accuracy: 0.7163 - val_loss: 0.9400 - val_categorical_accuracy: 0.6167 - lr: 3.1250e-05\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6799 - categorical_accuracy: 0.8166\n",
      "Epoch 00021: saving model to model_init_2022-12-1307_39_00.593560/model-00021-0.67993-0.81661-1.18790-0.53333.h5\n",
      "17/17 [==============================] - 77s 5s/step - loss: 0.6799 - categorical_accuracy: 0.8166 - val_loss: 1.1879 - val_categorical_accuracy: 0.5333 - lr: 3.1250e-05\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7631 - categorical_accuracy: 0.7509\n",
      "Epoch 00022: saving model to model_init_2022-12-1307_39_00.593560/model-00022-0.76314-0.75087-1.06389-0.61667.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.7631 - categorical_accuracy: 0.7509 - val_loss: 1.0639 - val_categorical_accuracy: 0.6167 - lr: 3.1250e-05\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6540 - categorical_accuracy: 0.8028\n",
      "Epoch 00023: saving model to model_init_2022-12-1307_39_00.593560/model-00023-0.65401-0.80277-1.01619-0.58333.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.6540 - categorical_accuracy: 0.8028 - val_loss: 1.0162 - val_categorical_accuracy: 0.5833 - lr: 1.5625e-05\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7626 - categorical_accuracy: 0.7543\n",
      "Epoch 00024: saving model to model_init_2022-12-1307_39_00.593560/model-00024-0.76264-0.75433-1.05556-0.58333.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.7626 - categorical_accuracy: 0.7543 - val_loss: 1.0556 - val_categorical_accuracy: 0.5833 - lr: 1.5625e-05\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6565 - categorical_accuracy: 0.8028\n",
      "Epoch 00025: saving model to model_init_2022-12-1307_39_00.593560/model-00025-0.65650-0.80277-0.96383-0.66667.h5\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.6565 - categorical_accuracy: 0.8028 - val_loss: 0.9638 - val_categorical_accuracy: 0.6667 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using custom conv2D and LSTM also the model tends to overfitts.\n",
    "\n",
    "### categorical_accuracy: 0.8028\n",
    "### val_categorical_accuracy: 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are using GRU insted of LSTM and checking for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_13 (TimeDi  (None, 30, 120, 120, 8)  224       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_14 (TimeDi  (None, 30, 120, 120, 8)  32        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 30, 60, 60, 8)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 30, 60, 60, 16)   1168      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 30, 60, 60, 16)   64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 30, 30, 30, 16)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 30, 30, 30, 32)   4640      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 30, 30, 30, 32)   128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 30, 15, 15, 32)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 30, 15, 15, 64)   18496     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 30, 15, 15, 64)   256       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 30, 7, 7, 64)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_25 (TimeDi  (None, 30, 7, 7, 128)    73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_26 (TimeDi  (None, 30, 7, 7, 128)    512       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_27 (TimeDi  (None, 30, 3, 3, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_28 (TimeDi  (None, 30, 1152)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                233856    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337,717\n",
      "Trainable params: 337,221\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Let us experiment different x,y,z value in the CNNLSTM network and find tune all the image size & Hyperparameters later\n",
    "\n",
    "x = 30 # number of frames\n",
    "y = 120 # image width\n",
    "z = 120 # image height\n",
    "\n",
    "# Input all the images sequencial by building the layer with dropouts and batchnormalisation\n",
    "\n",
    "model_5 = Sequential()   \n",
    "model_5.add(TimeDistributed(Conv2D(8, (3, 3),padding='same', activation='relu'),input_shape=(x,y,z,3)))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_5.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu')))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_5.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_5.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model_5.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model_5.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_5.add(GRU(64))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "# Dense layer \n",
    "model_5.add(Dense(64,activation='relu'))\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "# Softmax layer\n",
    "model_5.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Adam optimiser\n",
    "\n",
    "optimiser = 'Adam'  #write your optimizer\n",
    "model_5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us train and validate the model \n",
    "batch_size = 40\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /datasets/Project_data/train ; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/532295929.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_5 = model_5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5430 - categorical_accuracy: 0.3454Source path =  /datasets/Project_data/val ; batch size = 40\n",
      "\n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-1.54301-0.34540-1.93232-0.24000.h5\n",
      "17/17 [==============================] - 168s 10s/step - loss: 1.5430 - categorical_accuracy: 0.3454 - val_loss: 1.9323 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1385 - categorical_accuracy: 0.5217\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.13847-0.52174-2.35733-0.23333.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 1.1385 - categorical_accuracy: 0.5217 - val_loss: 2.3573 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0680 - categorical_accuracy: 0.5504\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.06805-0.55041-2.27398-0.26667.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 93s 6s/step - loss: 1.0680 - categorical_accuracy: 0.5504 - val_loss: 2.2740 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9663 - categorical_accuracy: 0.6254\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-0.96634-0.62539-2.31321-0.31667.h5\n",
      "17/17 [==============================] - 86s 5s/step - loss: 0.9663 - categorical_accuracy: 0.6254 - val_loss: 2.3132 - val_categorical_accuracy: 0.3167 - lr: 5.0000e-04\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8630 - categorical_accuracy: 0.6773\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-0.86303-0.67732-2.03658-0.35000.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 83s 5s/step - loss: 0.8630 - categorical_accuracy: 0.6773 - val_loss: 2.0366 - val_categorical_accuracy: 0.3500 - lr: 5.0000e-04\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7525 - categorical_accuracy: 0.7336\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-0.75254-0.73356-2.33881-0.21667.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.7525 - categorical_accuracy: 0.7336 - val_loss: 2.3388 - val_categorical_accuracy: 0.2167 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7741 - categorical_accuracy: 0.7093\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-0.77413-0.70934-2.03597-0.18333.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 74s 5s/step - loss: 0.7741 - categorical_accuracy: 0.7093 - val_loss: 2.0360 - val_categorical_accuracy: 0.1833 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5865 - categorical_accuracy: 0.7958\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.58654-0.79585-1.97263-0.25000.h5\n",
      "17/17 [==============================] - 75s 5s/step - loss: 0.5865 - categorical_accuracy: 0.7958 - val_loss: 1.9726 - val_categorical_accuracy: 0.2500 - lr: 1.2500e-04\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6567 - categorical_accuracy: 0.7336\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.65675-0.73356-2.31738-0.21667.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.6567 - categorical_accuracy: 0.7336 - val_loss: 2.3174 - val_categorical_accuracy: 0.2167 - lr: 1.2500e-04\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6211 - categorical_accuracy: 0.7855\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.62108-0.78547-1.95234-0.30000.h5\n",
      "17/17 [==============================] - 75s 5s/step - loss: 0.6211 - categorical_accuracy: 0.7855 - val_loss: 1.9523 - val_categorical_accuracy: 0.3000 - lr: 6.2500e-05\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6042 - categorical_accuracy: 0.7474\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.60423-0.74740-1.96061-0.35000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.6042 - categorical_accuracy: 0.7474 - val_loss: 1.9606 - val_categorical_accuracy: 0.3500 - lr: 6.2500e-05\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5991 - categorical_accuracy: 0.7889\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.59912-0.78893-1.80776-0.36667.h5\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.5991 - categorical_accuracy: 0.7889 - val_loss: 1.8078 - val_categorical_accuracy: 0.3667 - lr: 3.1250e-05\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5053 - categorical_accuracy: 0.8235\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.50533-0.82353-1.65689-0.41667.h5\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.5053 - categorical_accuracy: 0.8235 - val_loss: 1.6569 - val_categorical_accuracy: 0.4167 - lr: 3.1250e-05\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5879 - categorical_accuracy: 0.7958\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.58790-0.79585-1.69427-0.43333.h5\n",
      "17/17 [==============================] - 75s 5s/step - loss: 0.5879 - categorical_accuracy: 0.7958 - val_loss: 1.6943 - val_categorical_accuracy: 0.4333 - lr: 3.1250e-05\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5410 - categorical_accuracy: 0.8062\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.54104-0.80623-1.21840-0.53333.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.5410 - categorical_accuracy: 0.8062 - val_loss: 1.2184 - val_categorical_accuracy: 0.5333 - lr: 3.1250e-05\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5271 - categorical_accuracy: 0.8304\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.52713-0.83045-1.43832-0.51667.h5\n",
      "17/17 [==============================] - 75s 5s/step - loss: 0.5271 - categorical_accuracy: 0.8304 - val_loss: 1.4383 - val_categorical_accuracy: 0.5167 - lr: 3.1250e-05\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5000 - categorical_accuracy: 0.8478\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.50003-0.84775-1.22453-0.60000.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.5000 - categorical_accuracy: 0.8478 - val_loss: 1.2245 - val_categorical_accuracy: 0.6000 - lr: 3.1250e-05\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5043 - categorical_accuracy: 0.8339\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.50433-0.83391-1.35041-0.51667.h5\n",
      "17/17 [==============================] - 73s 5s/step - loss: 0.5043 - categorical_accuracy: 0.8339 - val_loss: 1.3504 - val_categorical_accuracy: 0.5167 - lr: 1.5625e-05\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4817 - categorical_accuracy: 0.8270\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.48168-0.82699-0.91764-0.61667.h5\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.4817 - categorical_accuracy: 0.8270 - val_loss: 0.9176 - val_categorical_accuracy: 0.6167 - lr: 1.5625e-05\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5010 - categorical_accuracy: 0.8270\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.50099-0.82699-1.14964-0.55000.h5\n",
      "17/17 [==============================] - 75s 5s/step - loss: 0.5010 - categorical_accuracy: 0.8270 - val_loss: 1.1496 - val_categorical_accuracy: 0.5500 - lr: 1.5625e-05\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5036 - categorical_accuracy: 0.8443\n",
      "Epoch 00021: saving model to model_init_2022-12-1307_39_00.593560/model-00021-0.50359-0.84429-1.00188-0.58333.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.5036 - categorical_accuracy: 0.8443 - val_loss: 1.0019 - val_categorical_accuracy: 0.5833 - lr: 1.5625e-05\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5201 - categorical_accuracy: 0.8408\n",
      "Epoch 00022: saving model to model_init_2022-12-1307_39_00.593560/model-00022-0.52010-0.84083-0.93624-0.58333.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.5201 - categorical_accuracy: 0.8408 - val_loss: 0.9362 - val_categorical_accuracy: 0.5833 - lr: 7.8125e-06\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.8443\n",
      "Epoch 00023: saving model to model_init_2022-12-1307_39_00.593560/model-00023-0.45680-0.84429-0.88207-0.63333.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.4568 - categorical_accuracy: 0.8443 - val_loss: 0.8821 - val_categorical_accuracy: 0.6333 - lr: 7.8125e-06\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5468 - categorical_accuracy: 0.7958\n",
      "Epoch 00024: saving model to model_init_2022-12-1307_39_00.593560/model-00024-0.54680-0.79585-0.79081-0.68333.h5\n",
      "17/17 [==============================] - 76s 5s/step - loss: 0.5468 - categorical_accuracy: 0.7958 - val_loss: 0.7908 - val_categorical_accuracy: 0.6833 - lr: 7.8125e-06\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4729 - categorical_accuracy: 0.8824\n",
      "Epoch 00025: saving model to model_init_2022-12-1307_39_00.593560/model-00025-0.47293-0.88235-0.87497-0.66667.h5\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.4729 - categorical_accuracy: 0.8824 - val_loss: 0.8750 - val_categorical_accuracy: 0.6667 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is better in terms of train_accuracy and it tends to overfitts\n",
    "\n",
    "### categorical_accuracy: 0.8824\n",
    "### val_categorical_accuracy: 0.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let we do the generators and input the images as we see that our images have two different sizes. \n",
    "x = 30 # No. of frames images\n",
    "y = 120 # Width of the image\n",
    "z = 120 # height\n",
    "\n",
    "def generatorWithAugmentation(source_path, folder_list, batch_size):\n",
    "    img_idx = [x for x in range(0,x)] #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            \n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # Let us resize all the images \n",
    "                    \n",
    "                    shifted = cv2.warpAffine(image, np.float32([[1, 0, np.random.randint(-20,20)],[0, 1, np.random.randint(-20,20)]]),(image.shape[1], image.shape[0]))\n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    resized_image = imresize(cropped,(y,z))\n",
    "                    resized_image = resized_image/255\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])#normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])#normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches        \n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    shifted = cv2.warpAffine(image, np.float32([[1, 0, np.random.randint(-20,20)],[0, 1, np.random.randint(-20,20)]]),(image.shape[1], image.shape[0]))\n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    resized_image = imresize(cropped,(y,z))\n",
    "                    resized_image = resized_image/255\n",
    "                                        \n",
    "                    batch_data[folder,idx,:,:,0] = (resized_image[:,:,0])\n",
    "                    batch_data[folder,idx,:,:,1] = (resized_image[:,:,1])\n",
    "                    batch_data[folder,idx,:,:,2] = (resized_image[:,:,2])\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the first overfitted model with augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_15 (Conv3D)          (None, 30, 120, 120, 8)   656       \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 30, 120, 120, 8)  32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 30, 120, 120, 8)   0         \n",
      "                                                                 \n",
      " conv3d_16 (Conv3D)          (None, 30, 120, 120, 16)  3472      \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 30, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 30, 120, 120, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_12 (MaxPoolin  (None, 15, 60, 60, 16)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_17 (Conv3D)          (None, 15, 60, 60, 32)    4128      \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 15, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 15, 60, 60, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_13 (MaxPoolin  (None, 7, 30, 30, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_18 (Conv3D)          (None, 7, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 7, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 7, 30, 30, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_14 (MaxPoolin  (None, 3, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_19 (Conv3D)          (None, 3, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 3, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 3, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_15 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1000)              6273000   \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 2505      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,867,365\n",
      "Trainable params: 6,866,869\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#write your model here\n",
    "model_aug = Sequential()       \n",
    "model_aug.add(Conv3D(8,kernel_size=(3,3,3),input_shape=(30, 120, 120, 3),padding='same'))\n",
    "model_aug.add(BatchNormalization())\n",
    "model_aug.add(Activation('relu'))\n",
    "\n",
    "model_aug.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(BatchNormalization())\n",
    "model_aug.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_aug.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(BatchNormalization())\n",
    "model_aug.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_aug.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(BatchNormalization())\n",
    "model_aug.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_aug.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(BatchNormalization())\n",
    "model_aug.add(MaxPooling3D(pool_size=(2, 2, 2)))      \n",
    "\n",
    "# Flatten layer \n",
    "\n",
    "model_aug.add(Flatten())\n",
    "\n",
    "model_aug.add(Dense(1000, activation='relu'))\n",
    "model_aug.add(Dropout(0.5))\n",
    "\n",
    "model_aug.add(Dense(500, activation='relu'))\n",
    "model_aug.add(Dropout(0.5))\n",
    "\n",
    "#Softmax layer\n",
    "\n",
    "model_aug.add(Dense(5, activation='softmax'))\n",
    "\n",
    "optimiser = 'Adam'\n",
    "model_aug.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_aug.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Let us see the Validate the Losses and put back the checkpoint\n",
    "\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "\n",
    "train_generator = generatorWithAugmentation(train_path, train_doc, batch_size)\n",
    "val_generator = generatorWithAugmentation(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/718867244.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history_aug = model_aug.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 8.2789 - categorical_accuracy: 0.3183 \n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-8.27890-0.31825-2.18352-0.19000.h5\n",
      "17/17 [==============================] - 196s 12s/step - loss: 8.2789 - categorical_accuracy: 0.3183 - val_loss: 2.1835 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 2.1166 - categorical_accuracy: 0.4373\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-2.11658-0.43734-3.05441-0.11667.h5\n",
      "17/17 [==============================] - 121s 8s/step - loss: 2.1166 - categorical_accuracy: 0.4373 - val_loss: 3.0544 - val_categorical_accuracy: 0.1167 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.7424 - categorical_accuracy: 0.5232\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.74238-0.52316-2.55487-0.23333.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 111s 7s/step - loss: 1.7424 - categorical_accuracy: 0.5232 - val_loss: 2.5549 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.6278 - categorical_accuracy: 0.5046\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.62785-0.50464-3.52158-0.21667.h5\n",
      "17/17 [==============================] - 101s 6s/step - loss: 1.6278 - categorical_accuracy: 0.5046 - val_loss: 3.5216 - val_categorical_accuracy: 0.2167 - lr: 5.0000e-04\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2974 - categorical_accuracy: 0.5623\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.29741-0.56230-4.33549-0.23333.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 105s 7s/step - loss: 1.2974 - categorical_accuracy: 0.5623 - val_loss: 4.3355 - val_categorical_accuracy: 0.2333 - lr: 5.0000e-04\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0132 - categorical_accuracy: 0.5986\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-1.01322-0.59862-4.61901-0.21667.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 1.0132 - categorical_accuracy: 0.5986 - val_loss: 4.6190 - val_categorical_accuracy: 0.2167 - lr: 2.5000e-04\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9304 - categorical_accuracy: 0.6747\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-0.93041-0.67474-5.86063-0.21667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.9304 - categorical_accuracy: 0.6747 - val_loss: 5.8606 - val_categorical_accuracy: 0.2167 - lr: 2.5000e-04\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8296 - categorical_accuracy: 0.6886\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.82963-0.68858-6.53777-0.23333.h5\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.8296 - categorical_accuracy: 0.6886 - val_loss: 6.5378 - val_categorical_accuracy: 0.2333 - lr: 1.2500e-04\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7515 - categorical_accuracy: 0.7301\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.75149-0.73010-5.20479-0.23333.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 100s 6s/step - loss: 0.7515 - categorical_accuracy: 0.7301 - val_loss: 5.2048 - val_categorical_accuracy: 0.2333 - lr: 1.2500e-04\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8310 - categorical_accuracy: 0.6920\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.83097-0.69204-6.06082-0.31667.h5\n",
      "17/17 [==============================] - 91s 6s/step - loss: 0.8310 - categorical_accuracy: 0.6920 - val_loss: 6.0608 - val_categorical_accuracy: 0.3167 - lr: 6.2500e-05\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7749 - categorical_accuracy: 0.7163\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.77489-0.71626-6.47336-0.25000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.7749 - categorical_accuracy: 0.7163 - val_loss: 6.4734 - val_categorical_accuracy: 0.2500 - lr: 6.2500e-05\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7729 - categorical_accuracy: 0.7024\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.77286-0.70242-6.23080-0.28333.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.7729 - categorical_accuracy: 0.7024 - val_loss: 6.2308 - val_categorical_accuracy: 0.2833 - lr: 3.1250e-05\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6126 - categorical_accuracy: 0.7647\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.61265-0.76471-6.08535-0.25000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.6126 - categorical_accuracy: 0.7647 - val_loss: 6.0853 - val_categorical_accuracy: 0.2500 - lr: 3.1250e-05\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6643 - categorical_accuracy: 0.7509\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.66434-0.75087-5.97025-0.26667.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.6643 - categorical_accuracy: 0.7509 - val_loss: 5.9702 - val_categorical_accuracy: 0.2667 - lr: 1.5625e-05\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6188 - categorical_accuracy: 0.7474\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.61882-0.74740-5.49056-0.30000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 89s 6s/step - loss: 0.6188 - categorical_accuracy: 0.7474 - val_loss: 5.4906 - val_categorical_accuracy: 0.3000 - lr: 1.5625e-05\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6628 - categorical_accuracy: 0.7301\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.66279-0.73010-5.68493-0.26667.h5\n",
      "17/17 [==============================] - 101s 6s/step - loss: 0.6628 - categorical_accuracy: 0.7301 - val_loss: 5.6849 - val_categorical_accuracy: 0.2667 - lr: 7.8125e-06\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6552 - categorical_accuracy: 0.7301\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.65519-0.73010-4.82625-0.26667.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.6552 - categorical_accuracy: 0.7301 - val_loss: 4.8262 - val_categorical_accuracy: 0.2667 - lr: 7.8125e-06\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7016 - categorical_accuracy: 0.7405\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.70160-0.74048-4.64387-0.28333.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.7016 - categorical_accuracy: 0.7405 - val_loss: 4.6439 - val_categorical_accuracy: 0.2833 - lr: 3.9063e-06\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6593 - categorical_accuracy: 0.7543\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.65927-0.75433-4.41648-0.38333.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "17/17 [==============================] - 91s 6s/step - loss: 0.6593 - categorical_accuracy: 0.7543 - val_loss: 4.4165 - val_categorical_accuracy: 0.3833 - lr: 3.9063e-06\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6496 - categorical_accuracy: 0.7543\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.64963-0.75433-3.91787-0.23333.h5\n",
      "17/17 [==============================] - 101s 6s/step - loss: 0.6496 - categorical_accuracy: 0.7543 - val_loss: 3.9179 - val_categorical_accuracy: 0.2333 - lr: 1.9531e-06\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6401 - categorical_accuracy: 0.7509\n",
      "Epoch 00021: saving model to model_init_2022-12-1307_39_00.593560/model-00021-0.64011-0.75087-3.64811-0.30000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "17/17 [==============================] - 92s 6s/step - loss: 0.6401 - categorical_accuracy: 0.7509 - val_loss: 3.6481 - val_categorical_accuracy: 0.3000 - lr: 1.9531e-06\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5698 - categorical_accuracy: 0.8097\n",
      "Epoch 00022: saving model to model_init_2022-12-1307_39_00.593560/model-00022-0.56983-0.80969-3.42091-0.38333.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.5698 - categorical_accuracy: 0.8097 - val_loss: 3.4209 - val_categorical_accuracy: 0.3833 - lr: 9.7656e-07\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5151 - categorical_accuracy: 0.7820\n",
      "Epoch 00023: saving model to model_init_2022-12-1307_39_00.593560/model-00023-0.51511-0.78201-2.67658-0.40000.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.5151 - categorical_accuracy: 0.7820 - val_loss: 2.6766 - val_categorical_accuracy: 0.4000 - lr: 9.7656e-07\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6595 - categorical_accuracy: 0.7336\n",
      "Epoch 00024: saving model to model_init_2022-12-1307_39_00.593560/model-00024-0.65949-0.73356-2.32994-0.43333.h5\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.6595 - categorical_accuracy: 0.7336 - val_loss: 2.3299 - val_categorical_accuracy: 0.4333 - lr: 4.8828e-07\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6201 - categorical_accuracy: 0.7439\n",
      "Epoch 00025: saving model to model_init_2022-12-1307_39_00.593560/model-00025-0.62014-0.74394-2.11955-0.48333.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.6201 - categorical_accuracy: 0.7439 - val_loss: 2.1195 - val_categorical_accuracy: 0.4833 - lr: 4.8828e-07\n"
     ]
    }
   ],
   "source": [
    "history_aug = model_aug.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is not helping with the base model and using augumentation also hece we will shift to transfer learning\n",
    "\n",
    "### categorical_accuracy: 0.7439\n",
    "### val_categorical_accuracy: 0.4833"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using of transfer learning wit LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 1s 0us/step\n",
      "17235968/17225924 [==============================] - 1s 0us/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_29 (TimeDi  (None, 30, 3, 3, 1024)   3228864   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_30 (TimeDi  (None, 30, 3, 3, 1024)   4096      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_31 (TimeDi  (None, 30, 1, 1, 1024)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_32 (TimeDi  (None, 30, 1024)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                278784    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,516,229\n",
      "Trainable params: 285,317\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = 30 # No. of frames images\n",
    "y = 120 # Width of the image\n",
    "z = 120 # height\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "model_6 = Sequential()\n",
    "model_6.add(TimeDistributed(mobilenet_transfer,input_shape=(30,120,120,3)))\n",
    "        \n",
    "        \n",
    "for layer in model_6.layers:\n",
    "    layer.trainable = False\n",
    "        \n",
    "        \n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_6.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_6.add(LSTM(64))\n",
    "model_6.add(Dropout(0.25))\n",
    "        \n",
    "model_6.add(Dense(64,activation='relu'))\n",
    "model_6.add(Dropout(0.25))\n",
    "        \n",
    "model_6.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "optimiser = 'Adam'\n",
    "model_6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_6.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "\n",
    "train_generator = generatorWithAugmentation(train_path, train_doc, batch_size)\n",
    "val_generator = generatorWithAugmentation(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/2698002504.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5468 - categorical_accuracy: 0.3107 \n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-1.54680-0.31071-1.43610-0.43000.h5\n",
      "17/17 [==============================] - 203s 12s/step - loss: 1.5468 - categorical_accuracy: 0.3107 - val_loss: 1.4361 - val_categorical_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2373 - categorical_accuracy: 0.5064\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.23728-0.50639-1.05813-0.66667.h5\n",
      "17/17 [==============================] - 120s 8s/step - loss: 1.2373 - categorical_accuracy: 0.5064 - val_loss: 1.0581 - val_categorical_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0933 - categorical_accuracy: 0.5695\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.09335-0.56948-1.21902-0.45000.h5\n",
      "17/17 [==============================] - 112s 7s/step - loss: 1.0933 - categorical_accuracy: 0.5695 - val_loss: 1.2190 - val_categorical_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9196 - categorical_accuracy: 0.6563\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-0.91962-0.65635-0.89566-0.65000.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 0.9196 - categorical_accuracy: 0.6563 - val_loss: 0.8957 - val_categorical_accuracy: 0.6500 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7708 - categorical_accuracy: 0.7188\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-0.77078-0.71885-0.82124-0.71667.h5\n",
      "17/17 [==============================] - 105s 7s/step - loss: 0.7708 - categorical_accuracy: 0.7188 - val_loss: 0.8212 - val_categorical_accuracy: 0.7167 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6975 - categorical_accuracy: 0.7405\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-0.69746-0.74048-0.71694-0.73333.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 0.6975 - categorical_accuracy: 0.7405 - val_loss: 0.7169 - val_categorical_accuracy: 0.7333 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6360 - categorical_accuracy: 0.7543\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-0.63597-0.75433-0.78385-0.70000.h5\n",
      "17/17 [==============================] - 94s 6s/step - loss: 0.6360 - categorical_accuracy: 0.7543 - val_loss: 0.7838 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5514 - categorical_accuracy: 0.7958\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-0.55144-0.79585-0.61212-0.76667.h5\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.5514 - categorical_accuracy: 0.7958 - val_loss: 0.6121 - val_categorical_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.8166\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.48470-0.81661-0.93844-0.60000.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.4847 - categorical_accuracy: 0.8166 - val_loss: 0.9384 - val_categorical_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4393 - categorical_accuracy: 0.8651\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.43932-0.86505-0.67891-0.75000.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.4393 - categorical_accuracy: 0.8651 - val_loss: 0.6789 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3450 - categorical_accuracy: 0.9031\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.34496-0.90311-0.61469-0.71667.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 0.3450 - categorical_accuracy: 0.9031 - val_loss: 0.6147 - val_categorical_accuracy: 0.7167 - lr: 5.0000e-04\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3195 - categorical_accuracy: 0.9031\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.31948-0.90311-0.64541-0.70000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.3195 - categorical_accuracy: 0.9031 - val_loss: 0.6454 - val_categorical_accuracy: 0.7000 - lr: 5.0000e-04\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.8893\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.31295-0.88927-0.80012-0.63333.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.3130 - categorical_accuracy: 0.8893 - val_loss: 0.8001 - val_categorical_accuracy: 0.6333 - lr: 2.5000e-04\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3378 - categorical_accuracy: 0.9031\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.33782-0.90311-0.53043-0.71667.h5\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.3378 - categorical_accuracy: 0.9031 - val_loss: 0.5304 - val_categorical_accuracy: 0.7167 - lr: 2.5000e-04\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2584 - categorical_accuracy: 0.9308\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.25841-0.93080-0.57528-0.76667.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.2584 - categorical_accuracy: 0.9308 - val_loss: 0.5753 - val_categorical_accuracy: 0.7667 - lr: 2.5000e-04\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2194 - categorical_accuracy: 0.9343\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.21941-0.93426-0.61568-0.78333.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 100s 6s/step - loss: 0.2194 - categorical_accuracy: 0.9343 - val_loss: 0.6157 - val_categorical_accuracy: 0.7833 - lr: 2.5000e-04\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2199 - categorical_accuracy: 0.9446\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.21989-0.94464-0.68933-0.71667.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.2199 - categorical_accuracy: 0.9446 - val_loss: 0.6893 - val_categorical_accuracy: 0.7167 - lr: 1.2500e-04\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2071 - categorical_accuracy: 0.9550\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.20711-0.95502-0.55007-0.81667.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.2071 - categorical_accuracy: 0.9550 - val_loss: 0.5501 - val_categorical_accuracy: 0.8167 - lr: 1.2500e-04\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2151 - categorical_accuracy: 0.9481\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.21507-0.94810-0.56531-0.76667.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.2151 - categorical_accuracy: 0.9481 - val_loss: 0.5653 - val_categorical_accuracy: 0.7667 - lr: 6.2500e-05\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1979 - categorical_accuracy: 0.9446\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.19786-0.94464-0.87558-0.70000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 100s 6s/step - loss: 0.1979 - categorical_accuracy: 0.9446 - val_loss: 0.8756 - val_categorical_accuracy: 0.7000 - lr: 6.2500e-05\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2297 - categorical_accuracy: 0.9170\n",
      "Epoch 00021: saving model to model_init_2022-12-1307_39_00.593560/model-00021-0.22967-0.91695-0.61771-0.75000.h5\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.2297 - categorical_accuracy: 0.9170 - val_loss: 0.6177 - val_categorical_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1821 - categorical_accuracy: 0.9481\n",
      "Epoch 00022: saving model to model_init_2022-12-1307_39_00.593560/model-00022-0.18206-0.94810-0.63765-0.70000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "17/17 [==============================] - 102s 6s/step - loss: 0.1821 - categorical_accuracy: 0.9481 - val_loss: 0.6376 - val_categorical_accuracy: 0.7000 - lr: 3.1250e-05\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2364 - categorical_accuracy: 0.9343\n",
      "Epoch 00023: saving model to model_init_2022-12-1307_39_00.593560/model-00023-0.23637-0.93426-0.48976-0.80000.h5\n",
      "17/17 [==============================] - 92s 6s/step - loss: 0.2364 - categorical_accuracy: 0.9343 - val_loss: 0.4898 - val_categorical_accuracy: 0.8000 - lr: 1.5625e-05\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2076 - categorical_accuracy: 0.9446\n",
      "Epoch 00024: saving model to model_init_2022-12-1307_39_00.593560/model-00024-0.20756-0.94464-0.63377-0.71667.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.2076 - categorical_accuracy: 0.9446 - val_loss: 0.6338 - val_categorical_accuracy: 0.7167 - lr: 1.5625e-05\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1720 - categorical_accuracy: 0.9619\n",
      "Epoch 00025: saving model to model_init_2022-12-1307_39_00.593560/model-00025-0.17204-0.96194-0.51235-0.75000.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.1720 - categorical_accuracy: 0.9619 - val_loss: 0.5123 - val_categorical_accuracy: 0.7500 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "history = model_6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is performing Great in terms of train accuracy and not good  in test\n",
    "\n",
    "### categorical_accuracy: 0.9619\n",
    "### val_categorical_accuracy: 0.7500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(25)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_37 (TimeDi  (None, 30, 3, 3, 1024)   3228864   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_38 (TimeDi  (None, 30, 3, 3, 1024)   4096      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_39 (TimeDi  (None, 30, 1, 1, 1024)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_40 (TimeDi  (None, 30, 1024)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 64)                209280    \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,446,725\n",
      "Trainable params: 215,813\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model_7 = Sequential()\n",
    "model_7.add(TimeDistributed(mobilenet_transfer,input_shape=(30,120,120,3)))\n",
    " \n",
    "for layer in model_7.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_7.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_7.add(GRU(64))\n",
    "model_7.add(Dropout(0.5))\n",
    "        \n",
    "model_7.add(Dense(64,activation='relu'))\n",
    "model_7.add(Dropout(0.5))\n",
    "        \n",
    "model_7.add(Dense(5, activation='softmax'))\n",
    "        \n",
    "        \n",
    "optimiser = 'Adam'\n",
    "model_7.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "train_generator = generatorWithAugmentation(train_path, train_doc, batch_size)\n",
    "val_generator = generatorWithAugmentation(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_500/2382972693.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history2 = model_7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.8954 - categorical_accuracy: 0.2353 \n",
      "Epoch 00001: saving model to model_init_2022-12-1307_39_00.593560/model-00001-1.89543-0.23529-1.43213-0.37000.h5\n",
      "17/17 [==============================] - 201s 12s/step - loss: 1.8954 - categorical_accuracy: 0.2353 - val_loss: 1.4321 - val_categorical_accuracy: 0.3700 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.6619 - categorical_accuracy: 0.2992\n",
      "Epoch 00002: saving model to model_init_2022-12-1307_39_00.593560/model-00002-1.66191-0.29923-1.40526-0.38333.h5\n",
      "17/17 [==============================] - 120s 8s/step - loss: 1.6619 - categorical_accuracy: 0.2992 - val_loss: 1.4053 - val_categorical_accuracy: 0.3833 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.5089 - categorical_accuracy: 0.3488\n",
      "Epoch 00003: saving model to model_init_2022-12-1307_39_00.593560/model-00003-1.50888-0.34877-1.26841-0.56667.h5\n",
      "17/17 [==============================] - 113s 7s/step - loss: 1.5089 - categorical_accuracy: 0.3488 - val_loss: 1.2684 - val_categorical_accuracy: 0.5667 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.3097 - categorical_accuracy: 0.4489\n",
      "Epoch 00004: saving model to model_init_2022-12-1307_39_00.593560/model-00004-1.30974-0.44892-1.17516-0.55000.h5\n",
      "17/17 [==============================] - 112s 7s/step - loss: 1.3097 - categorical_accuracy: 0.4489 - val_loss: 1.1752 - val_categorical_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2685 - categorical_accuracy: 0.4665\n",
      "Epoch 00005: saving model to model_init_2022-12-1307_39_00.593560/model-00005-1.26850-0.46645-1.13751-0.56667.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 1.2685 - categorical_accuracy: 0.4665 - val_loss: 1.1375 - val_categorical_accuracy: 0.5667 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.1336 - categorical_accuracy: 0.5433\n",
      "Epoch 00006: saving model to model_init_2022-12-1307_39_00.593560/model-00006-1.13362-0.54325-0.98763-0.63333.h5\n",
      "17/17 [==============================] - 101s 6s/step - loss: 1.1336 - categorical_accuracy: 0.5433 - val_loss: 0.9876 - val_categorical_accuracy: 0.6333 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.2203 - categorical_accuracy: 0.5017\n",
      "Epoch 00007: saving model to model_init_2022-12-1307_39_00.593560/model-00007-1.22032-0.50173-0.84748-0.66667.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 1.2203 - categorical_accuracy: 0.5017 - val_loss: 0.8475 - val_categorical_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0429 - categorical_accuracy: 0.6228\n",
      "Epoch 00008: saving model to model_init_2022-12-1307_39_00.593560/model-00008-1.04295-0.62284-0.80078-0.76667.h5\n",
      "17/17 [==============================] - 100s 6s/step - loss: 1.0429 - categorical_accuracy: 0.6228 - val_loss: 0.8008 - val_categorical_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9752 - categorical_accuracy: 0.6367\n",
      "Epoch 00009: saving model to model_init_2022-12-1307_39_00.593560/model-00009-0.97515-0.63668-0.74623-0.76667.h5\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.9752 - categorical_accuracy: 0.6367 - val_loss: 0.7462 - val_categorical_accuracy: 0.7667 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8665 - categorical_accuracy: 0.6644\n",
      "Epoch 00010: saving model to model_init_2022-12-1307_39_00.593560/model-00010-0.86648-0.66436-0.62528-0.75000.h5\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.8665 - categorical_accuracy: 0.6644 - val_loss: 0.6253 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8136 - categorical_accuracy: 0.6920\n",
      "Epoch 00011: saving model to model_init_2022-12-1307_39_00.593560/model-00011-0.81363-0.69204-0.75013-0.68333.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.8136 - categorical_accuracy: 0.6920 - val_loss: 0.7501 - val_categorical_accuracy: 0.6833 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7589 - categorical_accuracy: 0.7059\n",
      "Epoch 00012: saving model to model_init_2022-12-1307_39_00.593560/model-00012-0.75892-0.70588-0.70013-0.70000.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "17/17 [==============================] - 99s 6s/step - loss: 0.7589 - categorical_accuracy: 0.7059 - val_loss: 0.7001 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7998 - categorical_accuracy: 0.7059\n",
      "Epoch 00013: saving model to model_init_2022-12-1307_39_00.593560/model-00013-0.79982-0.70588-0.56465-0.75000.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.7998 - categorical_accuracy: 0.7059 - val_loss: 0.5647 - val_categorical_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6564 - categorical_accuracy: 0.7439\n",
      "Epoch 00014: saving model to model_init_2022-12-1307_39_00.593560/model-00014-0.65643-0.74394-0.48483-0.83333.h5\n",
      "17/17 [==============================] - 103s 6s/step - loss: 0.6564 - categorical_accuracy: 0.7439 - val_loss: 0.4848 - val_categorical_accuracy: 0.8333 - lr: 5.0000e-04\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6477 - categorical_accuracy: 0.7578\n",
      "Epoch 00015: saving model to model_init_2022-12-1307_39_00.593560/model-00015-0.64765-0.75779-0.73906-0.68333.h5\n",
      "17/17 [==============================] - 96s 6s/step - loss: 0.6477 - categorical_accuracy: 0.7578 - val_loss: 0.7391 - val_categorical_accuracy: 0.6833 - lr: 5.0000e-04\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6305 - categorical_accuracy: 0.7474\n",
      "Epoch 00016: saving model to model_init_2022-12-1307_39_00.593560/model-00016-0.63051-0.74740-0.52253-0.76667.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "17/17 [==============================] - 103s 6s/step - loss: 0.6305 - categorical_accuracy: 0.7474 - val_loss: 0.5225 - val_categorical_accuracy: 0.7667 - lr: 5.0000e-04\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7059 - categorical_accuracy: 0.7405\n",
      "Epoch 00017: saving model to model_init_2022-12-1307_39_00.593560/model-00017-0.70592-0.74048-0.67385-0.71667.h5\n",
      "17/17 [==============================] - 100s 6s/step - loss: 0.7059 - categorical_accuracy: 0.7405 - val_loss: 0.6738 - val_categorical_accuracy: 0.7167 - lr: 2.5000e-04\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6091 - categorical_accuracy: 0.7785\n",
      "Epoch 00018: saving model to model_init_2022-12-1307_39_00.593560/model-00018-0.60910-0.77855-0.50707-0.78333.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.6091 - categorical_accuracy: 0.7785 - val_loss: 0.5071 - val_categorical_accuracy: 0.7833 - lr: 2.5000e-04\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6255 - categorical_accuracy: 0.7785\n",
      "Epoch 00019: saving model to model_init_2022-12-1307_39_00.593560/model-00019-0.62549-0.77855-0.65975-0.70000.h5\n",
      "17/17 [==============================] - 95s 6s/step - loss: 0.6255 - categorical_accuracy: 0.7785 - val_loss: 0.6598 - val_categorical_accuracy: 0.7000 - lr: 1.2500e-04\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5701 - categorical_accuracy: 0.7924\n",
      "Epoch 00020: saving model to model_init_2022-12-1307_39_00.593560/model-00020-0.57010-0.79239-0.59724-0.75000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "17/17 [==============================] - 101s 6s/step - loss: 0.5701 - categorical_accuracy: 0.7924 - val_loss: 0.5972 - val_categorical_accuracy: 0.7500 - lr: 1.2500e-04\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5465 - categorical_accuracy: 0.8201\n",
      "Epoch 00021: saving model to model_init_2022-12-1307_39_00.593560/model-00021-0.54653-0.82007-0.59059-0.78333.h5\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.5465 - categorical_accuracy: 0.8201 - val_loss: 0.5906 - val_categorical_accuracy: 0.7833 - lr: 6.2500e-05\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4568 - categorical_accuracy: 0.8685\n",
      "Epoch 00022: saving model to model_init_2022-12-1307_39_00.593560/model-00022-0.45678-0.86851-0.50046-0.75000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "17/17 [==============================] - 93s 6s/step - loss: 0.4568 - categorical_accuracy: 0.8685 - val_loss: 0.5005 - val_categorical_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5175 - categorical_accuracy: 0.8062\n",
      "Epoch 00023: saving model to model_init_2022-12-1307_39_00.593560/model-00023-0.51750-0.80623-0.61407-0.75000.h5\n",
      "17/17 [==============================] - 99s 6s/step - loss: 0.5175 - categorical_accuracy: 0.8062 - val_loss: 0.6141 - val_categorical_accuracy: 0.7500 - lr: 3.1250e-05\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5944 - categorical_accuracy: 0.8131\n",
      "Epoch 00024: saving model to model_init_2022-12-1307_39_00.593560/model-00024-0.59442-0.81315-0.43387-0.83333.h5\n",
      "17/17 [==============================] - 97s 6s/step - loss: 0.5944 - categorical_accuracy: 0.8131 - val_loss: 0.4339 - val_categorical_accuracy: 0.8333 - lr: 3.1250e-05\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4977 - categorical_accuracy: 0.8235\n",
      "Epoch 00025: saving model to model_init_2022-12-1307_39_00.593560/model-00025-0.49768-0.82353-0.56192-0.78333.h5\n",
      "17/17 [==============================] - 98s 6s/step - loss: 0.4977 - categorical_accuracy: 0.8235 - val_loss: 0.5619 - val_categorical_accuracy: 0.7833 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "history2 = model_7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=25, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we got the best train and test accuracy overall. Hence concluding the best model.\n",
    "\n",
    "### categorical_accuracy: 0.8235\n",
    "### val_categorical_accuracy: 0.7833\n",
    "\n",
    "### Loss also less in terms both loss = 0.4977 and val_loss = 0.4977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history2.history['categorical_accuracy']\n",
    "val_acc = history2.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "epochs_range = range(25)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
